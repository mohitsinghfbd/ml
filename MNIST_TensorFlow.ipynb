{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-f764d48fa1c4>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#mnist=input_data.read_data_sets(\"MNIST_data/\")\n",
    "mnist=input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x181a492278>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x1c2241c4e0>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x1c2241c588>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist   # HAS 70,000 IMAGES !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape   # 28*28 ,FLATTENED 55000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.validation.images.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.]]), (55000, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels, mnist.train.labels.shape#(55000,)    output is a 10 sized vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in multiclassification problems we want our output to be onehot encoded,output layer has 10 units,only one of them 1 others 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2c103da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_image=mnist.train.images[0]\n",
    "first_image=np.array(first_image,dtype='float')\n",
    "first_image=first_image.reshape((28,28))# from the flatenned image created an image\n",
    "plt.imshow(first_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Creating your own NN with Tensorflow !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  each image is flatenned to 784 so our input layer has 784 entries\n",
    "# we have 10 units in output layer -for classifying 1 out of 10 classes\n",
    "# lets take 2 hidden units with 256 units (totally random)\n",
    "\n",
    "\n",
    "# Lay 1 has 784*256 weights ans 1* 256 biases-which is initiali to ramdom values\n",
    "# Lay 2 has 256*256 weights ans 1* 256 biases-which is initiali to ramdom values\n",
    "# output has 256*10 weights and 1*10 biases-which is initiali to ramdom values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.157357   -0.56403667 -1.05047    ... -1.2217664   0.8629345\n",
      "  -0.43726406]\n",
      " [ 0.5229951  -0.28505456 -0.95764035 ... -1.1764257   1.2730539\n",
      "   0.3383443 ]\n",
      " [ 2.4287863  -0.68671596 -2.164815   ... -1.1487008   0.61201537\n",
      "   0.4100877 ]\n",
      " ...\n",
      " [ 1.3556172  -0.7056232   2.333279   ...  0.5281772  -0.3004942\n",
      "  -0.75858915]\n",
      " [ 0.6162004  -0.2528405  -0.24191122 ...  0.06954598 -3.0614164\n",
      "  -1.0921593 ]\n",
      " [-0.29123366 -0.7346627  -0.40572876 ...  0.60482204 -0.33599594\n",
      "  -1.203188  ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.random_normal([784,256]).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# not place holders as the user doesnt provide it to us\n",
    "n_input=784\n",
    "n_hidden_1=256\n",
    "n_hidden_2=256\n",
    "n_classes=10\n",
    "# both dictionaries\n",
    "weights={\n",
    "    'h1': tf.Variable(tf.random_normal([n_input,n_hidden_1])),# randomly select values from a normal distribution\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2,n_classes]))\n",
    "}\n",
    "biases={\n",
    "    'h1': tf.Variable(tf.random_normal([n_hidden_1])),# randomly select values from a normal distribution\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to visualise fwd propog .the initial input is 10000*784 the first layer has weights 784*256 these are matrix multiplied and add biases to it. similarly pass to next layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propogation(x,weights,biases):\n",
    "    in_layer1=tf.add(tf.matmul(x,weights['h1']),biases['h1'])\n",
    "    out_layer1=tf.nn.relu(in_layer1) # activation fxn ,relu=max(a,0)\n",
    "    \n",
    "    in_layer2=tf.add(tf.matmul(out_layer1,weights['h2']),biases['h2'])\n",
    "    out_layer2=tf.nn.relu(in_layer2)\n",
    "    \n",
    "    output=tf.add(tf.matmul(out_layer2,weights['out']),biases['out'])# not using any activation here\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# predictions using random weights\n",
    "x=tf.placeholder(\"float\",[None,n_input])# we always know the second dimension ->784 (flatenned image)\n",
    "# this x can sometimes be training data/testing data /validation, no of images may vary\n",
    "y=tf.placeholder(tf.int32,[None,n_classes]) # for each img output is a 10 sized vector\n",
    "# in above vector jahn pe 1 hai wo indedx answer hai\n",
    "pred=forward_propogation(x,weights,biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=tf.argmax(pred,1) # 1 is the axis we have to find max along each ROW\n",
    "# arg max find the index wherre maximun happens\n",
    "true_labels=tf.argmax(y,1)\n",
    "correct_predictions=tf.equal(predictions,true_labels)# . TAKES TESOR OBJECTS NOT ARRAYS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 6, 6, ..., 0, 2, 6]),\n",
       " array([7, 2, 1, ..., 4, 5, 6]),\n",
       " array([False, False, False, ..., False, False,  True]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_eval,labels,correct_pred=sess.run([predictions,true_labels,correct_predictions],feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "predictions_eval,labels,correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1054"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred.sum()# out of 10,000-this is wid entirely random images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the cross entropy cost -y(log(h))-(1-y)log(1-h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-f024a47a50eb>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y)\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))#taking mean of all 10000 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to reduce this cost by changing weights ?-> .   USE OPTIMISER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimize=optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1692.7025\n",
      "1040.5156\n",
      "784.7114\n",
      "667.4742\n",
      "501.5155\n",
      "338.17798\n",
      "243.80013\n",
      "208.55066\n",
      "199.40434\n",
      "184.32558\n",
      "160.3322\n",
      "140.01862\n",
      "125.872665\n",
      "115.77623\n",
      "108.40827\n",
      "102.11004\n",
      "95.745415\n",
      "89.46034\n",
      "83.88429\n",
      "79.37198\n",
      "75.90512\n",
      "73.23335\n",
      "71.072525\n",
      "69.287674\n",
      "67.49584\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    c,_=sess.run([cost,optimize],feed_dict={x:mnist.train.images,y:mnist.train.labels})\n",
    "    print(c)    # LESSER COST EACH TIME WE RUN IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q:    how does this optimizer know what variables to change ??\n",
    "## Sol:      by default all variables we create have a property trainable=True,\n",
    "   ##         so our optimiser finds all variables with trainable=True(defalult true) , AND FIND GRADIENT WRT TO ALL OF THEM !(all that variables should depend on cost also)\n",
    "   ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(784, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(256, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_4:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_5:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=tf.argmax(pred,1) # 1 is the axis we have to find max along each ROW\n",
    "# arg max find the index wherre maximun happens\n",
    "true_labels=tf.argmax(y,1)\n",
    "correct_predictions=tf.equal(predictions,true_labels)# . TAKES TESOR OBJECTS NOT ARRAYS \n",
    "predictions_eval,labels,correct_pred=sess.run([predictions,true_labels,correct_predictions],feed_dict={x:mnist.test.images,y:mnist.test.labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8546"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred.sum()# out of 10,000-this is wid entirely random images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # .  Batch gradient Descent   Quick updates to weights with smaller batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13857.49609157443\n",
      "4050.6920037624423\n",
      "2286.633392890817\n",
      "1563.4951497696889\n",
      "1236.3944485362565\n",
      "1117.0365695098294\n",
      "1044.3531660348863\n",
      "886.5900344739587\n",
      "861.0706519689703\n",
      "673.2890078932943\n",
      "639.5684163933498\n",
      "518.8369679651886\n",
      "478.5981503205443\n",
      "477.8576926258073\n",
      "377.27454022048516\n",
      "412.824699025162\n",
      "339.8830788304854\n",
      "255.39123320969912\n",
      "227.2581425698035\n",
      "296.19091669179505\n",
      "274.53088417631704\n",
      "187.1688380367971\n",
      "139.1691335565747\n",
      "146.21403339004996\n",
      "184.7215583707291\n"
     ]
    }
   ],
   "source": [
    "batch_size=100\n",
    "for i in range(25):# 25* 550 times                                         \n",
    "    num_batches=int(mnist.train.num_examples/batch_size)\n",
    "    total_cost=0\n",
    "    for j in range(num_batches):\n",
    "        batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "        c,_=sess.run([cost,optimize],feed_dict={x:batch_x,y:batch_y})\n",
    "        total_cost=total_cost+c\n",
    "    print(total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=tf.argmax(pred,1) # 1 is the axis we have to find max along each ROW\n",
    "# arg max find the index wherre maximun happens\n",
    "true_labels=tf.argmax(y,1)\n",
    "correct_predictions=tf.equal(predictions,true_labels)# . TAKES TESOR OBJECTS NOT ARRAYS \n",
    "predictions_eval,labels,correct_pred=sess.run([predictions,true_labels,correct_predictions],feed_dict={x:mnist.test.images,y:mnist.test.labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9489"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred.sum()# out of 10,000-this is wid entirely random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
